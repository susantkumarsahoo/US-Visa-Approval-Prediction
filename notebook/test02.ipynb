{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6038c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc18abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "mongo_db_url = os.getenv(\"MONGODB_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3dc0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "\n",
    "DATABASE_NAME = \"US_VISA\"\n",
    "\n",
    "COLLECTION_NAME = \"visa_data\"\n",
    "\n",
    "\n",
    "MONGODB_URL_KEY = \"MONGODB_URI\"\n",
    "\n",
    "\n",
    "PIPELINE_NAME: str = \"usvisa\"\n",
    "ARTIFACT_DIR: str = \"artifact\"\n",
    "\n",
    "MODEL_FILE_NAME = \"model.pkl\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data Ingestion related constant start with DATA_INGESTION VAR NAME\n",
    "\"\"\"\n",
    "DATA_INGESTION_COLLECTION_NAME: str = \"visa_data\"\n",
    "DATA_INGESTION_DIR_NAME: str = \"data_ingestion\"\n",
    "DATA_INGESTION_FEATURE_STORE_DIR: str = \"feature_store\"\n",
    "DATA_INGESTION_INGESTED_DIR: str = \"ingested\"\n",
    "DATA_INGESTION_TRAIN_TEST_SPLIT_RATIO: float = 0.2\n",
    "\n",
    "\n",
    "TARGET_COLUMN = \"case_status\"\n",
    "CURRENT_YEAR = date.today().year\n",
    "PREPROCSSING_OBJECT_FILE_NAME = \"preprocessing.pkl\"\n",
    "\n",
    "FILE_NAME: str = \"usvisa.csv\"\n",
    "TRAIN_FILE_NAME: str = \"train.csv\"\n",
    "TEST_FILE_NAME: str = \"test.csv\"\n",
    "SCHEMA_FILE_PATH = os.path.join(\"config\", \"schema.yaml\")\n",
    "\n",
    "\n",
    "import os\n",
    "from us_visa.constants import *\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "TIMESTAMP: str = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingPipelineConfig:\n",
    "    pipeline_name: str = PIPELINE_NAME\n",
    "    artifact_dir: str = os.path.join(ARTIFACT_DIR, TIMESTAMP)\n",
    "    timestamp: str = TIMESTAMP\n",
    "\n",
    "\n",
    "training_pipeline_config: TrainingPipelineConfig = TrainingPipelineConfig()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    data_ingestion_dir: str = os.path.join(training_pipeline_config.artifact_dir, DATA_INGESTION_DIR_NAME)\n",
    "    feature_store_file_path: str = os.path.join(data_ingestion_dir, DATA_INGESTION_FEATURE_STORE_DIR, FILE_NAME)\n",
    "    training_file_path: str = os.path.join(data_ingestion_dir, DATA_INGESTION_INGESTED_DIR, TRAIN_FILE_NAME)\n",
    "    testing_file_path: str = os.path.join(data_ingestion_dir, DATA_INGESTION_INGESTED_DIR, TEST_FILE_NAME)\n",
    "    train_test_split_ratio: float = DATA_INGESTION_TRAIN_TEST_SPLIT_RATIO\n",
    "    collection_name:str = DATA_INGESTION_COLLECTION_NAME\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionArtifact:\n",
    "    trained_file_path:str \n",
    "    test_file_path:str \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pymongo\n",
    "import certifi\n",
    "\n",
    "from us_visa.exception import USvisaException\n",
    "from us_visa.logger import logging\n",
    "from us_visa.constants import DATABASE_NAME, MONGODB_URL_KEY\n",
    "\n",
    "ca = certifi.where()\n",
    "\n",
    "class MongoDBClient:\n",
    "    \"\"\"\n",
    "    Class Name :   MongoDBClient\n",
    "    Description :   This class handles the MongoDB connection and provides \n",
    "                    access to the specified database.\n",
    "    \n",
    "    Output      :   Connection to MongoDB database\n",
    "    On Failure  :   Raises an exception\n",
    "    \"\"\"\n",
    "    client = None\n",
    "\n",
    "    def __init__(self, database_name: str = DATABASE_NAME) -> None:\n",
    "        try:\n",
    "            if MongoDBClient.client is None:\n",
    "                mongo_db_url = os.getenv(MONGODB_URL_KEY)\n",
    "                if mongo_db_url is None:\n",
    "                    raise Exception(f\"Environment key: {MONGODB_URL_KEY} is not set.\")\n",
    "                \n",
    "                MongoDBClient.client = pymongo.MongoClient(mongo_db_url, tlsCAFile=ca)\n",
    "            \n",
    "            self.client = MongoDBClient.client\n",
    "            self.database = self.client[database_name]\n",
    "            self.database_name = database_name\n",
    "            logging.info(f\"MongoDB connection successful to database: {database_name}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise USvisaException(e, sys)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from us_visa.configuration.mongo_db_connection import MongoDBClient\n",
    "from us_visa.constants import DATABASE_NAME\n",
    "from us_visa.exception import USvisaException\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class USvisaData:\n",
    "    \"\"\"\n",
    "    This class help to export entire mongo db record as pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.mongo_client = MongoDBClient(database_name=DATABASE_NAME)\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e,sys)\n",
    "        \n",
    "\n",
    "    def export_collection_as_dataframe(self,collection_name:str,database_name:Optional[str]=None)->pd.DataFrame:\n",
    "        try:\n",
    "            \"\"\"\n",
    "            export entire collectin as dataframe:\n",
    "            return pd.DataFrame of collection\n",
    "            \"\"\"\n",
    "            if database_name is None:\n",
    "                collection = self.mongo_client.database[collection_name]\n",
    "            else:\n",
    "                collection = self.mongo_client[database_name][collection_name]\n",
    "\n",
    "            df = pd.DataFrame(list(collection.find()))\n",
    "            if \"_id\" in df.columns.to_list():\n",
    "                df = df.drop(columns=[\"_id\"], axis=1)\n",
    "            df.replace({\"na\":np.nan},inplace=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e,sys)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from us_visa.entity.config_entity import DataIngestionConfig\n",
    "from us_visa.entity.artifact_entity import DataIngestionArtifact\n",
    "from us_visa.exception import USvisaException\n",
    "from us_visa.logger import logging\n",
    "from us_visa.data_access.usvisa_data import USvisaData\n",
    "\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self,data_ingestion_config:DataIngestionConfig=DataIngestionConfig()):\n",
    "        \"\"\"\n",
    "        :param data_ingestion_config: configuration for data ingestion\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data_ingestion_config = data_ingestion_config\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e,sys)\n",
    "\n",
    "    def export_data_into_feature_store(self)->DataFrame:\n",
    "        \"\"\"\n",
    "        Method Name :   export_data_into_feature_store\n",
    "        Description :   This method exports data from mongodb to csv file\n",
    "        \n",
    "        Output      :   data is returned as artifact of data ingestion components\n",
    "        On Failure  :   Write an exception log and then raise an exception\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Exporting data from mongodb\")\n",
    "            usvisa_data = USvisaData()\n",
    "            dataframe = usvisa_data.export_collection_as_dataframe(collection_name=\n",
    "                                                                   self.data_ingestion_config.collection_name)\n",
    "            logging.info(f\"Shape of dataframe: {dataframe.shape}\")\n",
    "            feature_store_file_path  = self.data_ingestion_config.feature_store_file_path\n",
    "            dir_path = os.path.dirname(feature_store_file_path)\n",
    "            os.makedirs(dir_path,exist_ok=True)\n",
    "            logging.info(f\"Saving exported data into feature store file path: {feature_store_file_path}\")\n",
    "            dataframe.to_csv(feature_store_file_path,index=False,header=True)\n",
    "            return dataframe\n",
    "\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e,sys)\n",
    "\n",
    "\n",
    "    def split_data_as_train_test(self,dataframe: DataFrame) ->None:\n",
    "        \"\"\"\n",
    "        Method Name :   split_data_as_train_test\n",
    "        Description :   This method splits the dataframe into train set and test set based on split ratio \n",
    "        \n",
    "        Output      :   Folder is created in s3 bucket\n",
    "        On Failure  :   Write an exception log and then raise an exception\n",
    "        \"\"\"\n",
    "        logging.info(\"Entered split_data_as_train_test method of Data_Ingestion class\")\n",
    "\n",
    "        try:\n",
    "            train_set, test_set = train_test_split(dataframe, test_size=self.data_ingestion_config.train_test_split_ratio)\n",
    "            logging.info(\"Performed train test split on the dataframe\")\n",
    "            logging.info(\n",
    "                \"Exited split_data_as_train_test method of Data_Ingestion class\"\n",
    "            )\n",
    "            dir_path = os.path.dirname(self.data_ingestion_config.training_file_path)\n",
    "            os.makedirs(dir_path,exist_ok=True)\n",
    "            \n",
    "            logging.info(f\"Exporting train and test file path.\")\n",
    "            train_set.to_csv(self.data_ingestion_config.training_file_path,index=False,header=True)\n",
    "            test_set.to_csv(self.data_ingestion_config.testing_file_path,index=False,header=True)\n",
    "\n",
    "            logging.info(f\"Exported train and test file path.\")\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e, sys) from e\n",
    "\n",
    "\n",
    "\n",
    "    def initiate_data_ingestion(self) ->DataIngestionArtifact:\n",
    "        \"\"\"\n",
    "        Method Name :   initiate_data_ingestion\n",
    "        Description :   This method initiates the data ingestion components of training pipeline \n",
    "        \n",
    "        Output      :   train set and test set are returned as the artifacts of data ingestion components\n",
    "        On Failure  :   Write an exception log and then raise an exception\n",
    "        \"\"\"\n",
    "        logging.info(\"Entered initiate_data_ingestion method of Data_Ingestion class\")\n",
    "\n",
    "        try:\n",
    "            dataframe = self.export_data_into_feature_store()\n",
    "\n",
    "            logging.info(\"Got the data from mongodb\")\n",
    "\n",
    "            self.split_data_as_train_test(dataframe)\n",
    "\n",
    "            logging.info(\"Performed train test split on the dataset\")\n",
    "\n",
    "            logging.info(\n",
    "                \"Exited initiate_data_ingestion method of Data_Ingestion class\"\n",
    "            )\n",
    "\n",
    "            data_ingestion_artifact = DataIngestionArtifact(trained_file_path=self.data_ingestion_config.training_file_path,\n",
    "            test_file_path=self.data_ingestion_config.testing_file_path)\n",
    "            \n",
    "            logging.info(f\"Data ingestion artifact: {data_ingestion_artifact}\")\n",
    "            return data_ingestion_artifact\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e, sys) from e\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "from us_visa.exception import USvisaException\n",
    "from us_visa.logger import logging\n",
    "\n",
    "from us_visa.components.data_ingestion import DataIngestion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from us_visa.entity.config_entity import DataIngestionConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from us_visa.entity.artifact_entity import DataIngestionArtifact\n",
    "                                            \n",
    "                                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrainPipeline:\n",
    "    def __init__(self):\n",
    "        self.data_ingestion_config = DataIngestionConfig()\n",
    "\n",
    "\n",
    "        \n",
    "    def start_data_ingestion(self) -> DataIngestionArtifact:\n",
    "        \"\"\"\n",
    "        This method of TrainPipeline class is responsible for starting data ingestion component\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"Entered the start_data_ingestion method of TrainPipeline class\")\n",
    "            logging.info(\"Getting the data from mongodb\")\n",
    "            data_ingestion = DataIngestion(data_ingestion_config=self.data_ingestion_config)\n",
    "            data_ingestion_artifact = data_ingestion.initiate_data_ingestion()\n",
    "            logging.info(\"Got the train_set and test_set from mongodb\")\n",
    "            logging.info(\n",
    "                \"Exited the start_data_ingestion method of TrainPipeline class\"\n",
    "            )\n",
    "            return data_ingestion_artifact\n",
    "        except Exception as e:\n",
    "            raise USvisaException(e, sys) from e\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_pipeline(self, ) -> None:\n",
    "        \"\"\"\n",
    "        This method of TrainPipeline class is responsible for running complete pipeline\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_ingestion_artifact = self.start_data_ingestion()        \n",
    "        except Exception as e:\n",
    "            raise USvisaException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "from us_visa.exception import USvisaException\n",
    "from us_visa.logger import logging\n",
    "\n",
    "from us_visa.pipline.training_pipeline import TrainPipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipline  = TrainPipeline()\n",
    "pipline.run_pipeline()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6651f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33ac48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d6ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279ee8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea87c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
